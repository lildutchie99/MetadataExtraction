import requests
from bs4 import BeautifulSoup, Comment
import string
import sys
import math

class Extract:

    """
    Takes optional paramaters for what year range to use in ngram retrieval
    """
    def __init__(self, ngram_year=2008, ngram_smooth=3):
        self.punctbl = str.maketrans(string.punctuation.replace("'", ''), " " * (len(string.punctuation)-1))
        self.ngram_year = ngram_year
        self.ngram_smooth = ngram_smooth

    """
    Generate a value representing a word's 'fitness' as a potential keyword, based on it's TF and IDF
    Will and should be adjusted
    """
    def tfidfComp(self, tf, idf):
        return tf/math.exp(idf)

    """
    @:param url: url of site to be mined
    @:return a dict including title, description, a list of images, and keywords
    """
    def mine(self, url):
        data = {'title':'', 'desc':'', 'imgs':[], 'kw':[]}
        tdict = {} #TF/IDF dictionary

        doc = BeautifulSoup(requests.get(url).content, 'html.parser').html
        #find all relevant text, excluding comments and scripts
        doctext = ' '.join(doc.findAll(text=lambda text: not (isinstance(text, Comment) or text.parent.name=='script')))

        doctext = doctext.translate(self.punctbl) #strip punctuation
        words = doctext.split()
        #calculate tf/retrieve idf
        for word in words:
            if word not in tdict:
                #retrieve unigram from Google
                print(word)
                resp = str(requests.get('https://books.google.com/ngrams/graph?content=%s&case_insensitive=on&year_start=%d&year_end=%d&corpus=15&smoothing=%d' % (word,self.ngram_year-1,self.ngram_year,self.ngram_smooth)).content)
                start_idx = resp.find('var data')

                if start_idx != -1:
                    freqdat= eval(resp[resp.find('[', start_idx):resp.find(';', start_idx)]) #take selection with relevant data
                    if freqdat == []: #blank response block
                        tdict[word] = {'tf':1, 'idf':None}
                    else:
                        try:
                            print(float(next(item for item in freqdat if item['type'] in ['CASE_INSENSITIVE', 'NGRAM'])['timeseries'][-1]))
                            tdict[word.lower()] = {'tf':1, 'idf':float(next(item for item in freqdat if item['type'] in ['CASE_INSENSITIVE', 'NGRAM'])['timeseries'][-1])}
                        except StopIteration:
                            print(freqdat)
                            sys.exit(1)
                else:  #not in dictionary (probably some proper noun or brand/service name)
                    if "try again later" in resp:
                        #raise Exception("API not giving responses.") #it doesn't seem to like automated requests...
                        words.append(word) #try again at end
                        print("No response, will try again.")
                        continue
                    tdict[word] = {'tf':1, 'idf':None} #don't convert to lowercase for proper noun
            else:
                tdict[word]['tf'] += 1

        print(tdict)

        minidf = min(tdict.items(), key=lambda item:item[1]['idf'] if item[1]['idf'] is not None else 100)[1]['idf']
        for key in tdict:
            if tdict[key]['idf']==None:
                tdict[key]['idf'] = minidf

        terms = sorted(tdict.items(), key=lambda el: self.tfidfComp(el[1]['tf'], el[1]['idf']), reverse=True) #sort descending by tf/idf ratio
        print(len(terms))
        print(terms)

        return data

#example
e = Extract()
e.mine('https://www.adxeed.com')